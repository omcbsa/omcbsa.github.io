<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width,initial-scale=1" />
  <title>Embodying Multi-Hand Manipulation Policies by Searching the Assignment and Null Spaces</title>
  <meta name="description" content="SEmbodying Multi-Hand Manipulation Policies by Searching the Assignment and Null Spaces." />
  <link rel="stylesheet" href="styles.css" />
</head>
<body>
  <header class="site-header">
    <div class="container">
      <h1>Embodying Multi-Hand Manipulation Policies by Searching the Assignment and Null Spaces</h1>
      <p class="tagline">Concise demonstrations and supporting videos</p>
    </div>
  </header>

  <main class="container">
    <section class="panel main-video">
      <div class="panel-header">
        <h2>A short introductory video</h2>
        <!-- <p class="muted">A short introductory video.</p> -->
      </div>

      <div class="preview">
        <!-- Main video loaded from assets directory (replace assets/main.mp4 as needed) -->
        <video id="main-video" controls playsinline preload="metadata" src="assets/main.mp4" aria-label="Main video">
          Your browser does not support the video element.
        </video>
      </div>
    </section>

    <section class="panel abstract">
      <h2>Short Description</h2>
      <div id="abstract" class="abstract-text" aria-label="Abstract">
        <p>
          Learned manipulation policies are increasingly capable of generating rich motions for abstract “hands” and are attractive in practice because they rely on easily collected demonstrations and transfer across robot platforms. Executing these trajectories on multi-arm robots, however, is not trivial. Multi-hand policy outputs must be assigned to physical arms, each arm must realize a configuration-space motion that tracks its prescribed end-effector trajectory, and all arms must respect kinematic limits and avoid collisions. In the absence of algorithms that directly address this problem, practitioners typically extend single-arm inverse-kinematics (IK) pipelines in an ad hoc way, with no guarantees of feasibility or safety. In this work, we close this execution gap with a search-based framework that is theoretically complete for grounding policy-generated multi-hand trajectories onto physical multi-arm systems. Building on Conflict-Based Search, our method explicitly searches over both the discrete assignment of trajectories to arms and the continuous Jacobian null spaces of redundant manipulators, using redundancy to avoid inter-arm collisions while tracking the prescribed motions. This unified treatment of assignment and null-space motion yields a practically efficient planner that safely realizes coordinated manipulation-policy outputs on multi-arm robots.
        </p>
      </div>
      <!-- <div class="hint muted">Tip: Update this description in the source when ready.</div> -->
    </section>

    <section class="panel experiments">
      <div class="panel-header">
        <h2>Physical Experiments</h2>
        <p class="muted">We tested our algorithm OM-CBSA on multiple manipulation tasks defined only as end-effector motions. We used a team of three Kinova Gen 3 robot arms.</p>
      </div>

      <div id="phys-grid" class="grid" aria-live="polite">
        <!-- Three physical experiment videos from assets -->
        <figure class="card">
          <video loop muted autoplay playsinline preload="metadata" src="assets/phys1.mp4" title="Pushing a book">Your browser does not support the video element.</video>
          <figcaption class="meta"><div>Pushing a book</div></figcaption>
        </figure>

        <figure class="card">
          <video loop muted autoplay playsinline preload="metadata" src="assets/phys2.mp4" title="Rotating a cloth">Your browser does not support the video element.</video>
          <figcaption class="meta"><div>Rotating a cloth</div></figcaption>
        </figure>

        <figure class="card">
          <video loop muted autoplay playsinline preload="metadata" src="assets/phys3.mp4" title="Flipping a box">Your browser does not support the video element.</video>
          <figcaption class="meta"><div>Flipping a box</div></figcaption>
        </figure>
      </div>
    </section>

    <section class="panel experiments">
      <div class="panel-header">
        <h2>Simulated Experiments</h2>
        <p class="muted">Three simulated experiment clips (loaded from /assets).</p>
      </div>

      <div id="sim-grid" class="grid" aria-live="polite">
        <!-- Three simulated experiment videos from assets -->
        <figure class="card">
          <video playsinline preload="metadata" src="assets/sim1.m4v" title="Simulated experiment 1">Your browser does not support the video element.</video>
          <figcaption class="meta"><div>Simulated experiment 1</div></figcaption>
        </figure>

        <figure class="card">
          <video playsinline preload="metadata" src="assets/sim2.m4v" title="Simulated experiment 2">Your browser does not support the video element.</video>
          <figcaption class="meta"><div>Simulated experiment 2</div></figcaption>
        </figure>

        <figure class="card">
          <video playsinline preload="metadata" src="assets/sim3.m4v" title="Simulated experiment 3">Your browser does not support the video element.</video>
          <figcaption class="meta"><div>Simulated experiment 3</div></figcaption>
        </figure>
      </div>
    </section>

    <footer class="foot-note">
      <div class="container">
        <small class="muted">This page is a lightweight supplementary site intended for quick browsing of media supporting a paper. When you are ready, push videos into an /assets directory in this repository and update filenames here.</small>
      </div>
    </footer>
  </main>

  <script src="script.js"></script>
</body>
</html>
